{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/dan/utils/dspix/geopix/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a list of image files and associated geojson files that contain the bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import ogr\n",
    "import re\n",
    "\n",
    "tifs = glob.glob('AOI_5_Khartoum_Train/RGB-PanSharpen/*.tif')\n",
    "geojsons = glob.glob('AOI_5_Khartoum_Train/geojson/buildings/*.geojson')\n",
    "\n",
    "tif_ids = [int(re.findall(r'\\d+', tif)[2]) for tif in tifs]\n",
    "geojson_ids = [int(re.findall(r'\\d+', js)[2]) for js in geojsons]\n",
    "\n",
    "files = [[tifs[i], geojsons[geojson_ids.index(id_)]] for i, id_ in enumerate(tif_ids)]\n",
    "\n",
    "files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = ogr.Open(files[0][1]) # The first geojson\n",
    "layer = geo.GetLayer()\n",
    "\n",
    "bboxes = []\n",
    "for feat in layer:\n",
    "    geom = feat.GetGeometryRef()\n",
    "    bbox = geom.GetEnvelope() # minX, maxX, minY, maxY\n",
    "    bboxes.append(bbox)\n",
    "\n",
    "bboxes[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the projected data to pixel coordinates we need the extent of the source image in projected coordinates, we also need to normalize so they are scaled between 0 and 1 (i.e. the *relative position on the image). So repeating with the coordinate transform we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopix as gp\n",
    "import gdal\n",
    "\n",
    "image = gdal.Open(files[0][0]) # The first image\n",
    "\n",
    "n_x = image.RasterXSize\n",
    "n_y = image.RasterYSize\n",
    "\n",
    "gt = image.GetGeoTransform()\n",
    "gref = gp.Georeference(gt)\n",
    "\n",
    "layer.ResetReading()\n",
    "\n",
    "bboxes = []\n",
    "for feat in layer:\n",
    "    geom = feat.GetGeometryRef()\n",
    "    min_x, max_x, min_y, max_y = geom.GetEnvelope()\n",
    "    \n",
    "    # Note that transforming to pixel coords shifts the origin to the top left corner\n",
    "    bbox = gref.world2pix([[min_x, max_y], [max_x, min_y]]).ravel() # minx, miny, maxx, maxy\n",
    "    bbox = bbox[[1, 0, 3, 2]] / [n_y, n_x, n_y, n_x]\n",
    "    bboxes.append(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "\n",
    "def scale_to_8bit(pix):\n",
    "    scaled = np.zeros(pix.shape, dtype=float)\n",
    "    for b in range(len(pix)):\n",
    "        scaled[b] = pix[b]/pix[b].max()\n",
    "    \n",
    "    return (scaled*255)\n",
    "\n",
    "bands = scale_to_8bit(image.ReadAsArray())\n",
    "tcc = bands[:3].transpose(1, 2, 0)\n",
    "\n",
    "def draw_boxes(bboxes, ax):\n",
    "    '''Draws on the axis image'''\n",
    "    for box in bboxes:\n",
    "        xy = box[[1, 0]] * [n_x, n_y]\n",
    "        w = (box[3]-box[1]) * n_x\n",
    "        h = (box[2]-box[0]) * n_y\n",
    "        rect = patches.Rectangle(xy, w, h, lw=1, ec='r', fc='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(tcc.astype(int))\n",
    "draw_boxes(bboxes, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geojson_to_bboxes(geojson_fn, georef, nx, ny):\n",
    "    '''\n",
    "    '''\n",
    "    json = ogr.Open(geojson_fn)\n",
    "    layer = json.GetLayer()\n",
    "    bboxes = []\n",
    "    for feat in layer:\n",
    "        geom = feat.GetGeometryRef()\n",
    "        min_x, max_x, min_y, max_y = geom.GetEnvelope()\n",
    "        bbox = georef.world2pix([[min_x, max_y], [max_x, min_y]]).ravel() # minx, miny, maxx, maxy\n",
    "        bbox = bbox[[1, 0, 3, 2]] / [ny, nx, ny, nx]\n",
    "        bboxes.append(bbox) # ymin, xmin, ymax, xmax\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "np.stack(geojson_to_bboxes(files[0][1], gref, n_x, n_y))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write functions to encode the image data into an `uint8` array with shape (rows, columns, bands) and the bounding boxes for each object. See https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_list(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64_list(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _bytes_list(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def encode_sample(name, pixels, boxes):\n",
    "    '''Creates a tf.Example proto from image data and boxes.\n",
    "    Args:\n",
    "        name: The image filename.\n",
    "        pixels: A numpy array of image data of shape (rows, columns, bands)\n",
    "        boxes: A numpy array of n boxes with shape (ymin, xmin, ymax, xmax)\n",
    "    \n",
    "    Returns:\n",
    "        example: The tf.Example created.\n",
    "    '''\n",
    "    rows, cols, bands = pixels.shape\n",
    "    \n",
    "    xmins = boxes[:, 1]\n",
    "    xmaxs = boxes[:, 3]\n",
    "    ymins = boxes[:, 0]\n",
    "    ymaxs = boxes[:, 2]\n",
    "    classes_text = ['building'.encode('utf8')]*len(boxes)\n",
    "    classes = [1]*len(boxes)\n",
    "    \n",
    "    encode_pixels_as_jpeg = tf.image.encode_jpeg(\n",
    "        tf.convert_to_tensor(pixels.astype(np.uint8), dtype=tf.uint8)\n",
    "    ).numpy() # Expects an encoded jpeg (bytes)\n",
    "    \n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                'image/source_id': _bytes(name.encode('utf8')),\n",
    "                'image/filename': _bytes(name.encode('utf8')),\n",
    "                'image/height': _int64(rows),\n",
    "                'image/width': _int64(cols),\n",
    "                'image/depth': _int64(bands),\n",
    "                'image/encoded': _bytes(encode_pixels_as_jpeg),\n",
    "                #'image/label': _bytes(labels.astype(np.uint8).tobytes()),\n",
    "                'image/format': _bytes('JPEG'.encode('utf8')), # Hardcoded\n",
    "                'image/object/bbox/xmin': _float_list(xmins),\n",
    "                'image/object/bbox/xmax': _float_list(xmaxs),\n",
    "                'image/object/bbox/ymin': _float_list(ymins),\n",
    "                'image/object/bbox/ymax': _float_list(ymaxs),\n",
    "                'image/object/class/text': _bytes_list(classes_text),\n",
    "                'image/object/class/label': _int64_list(classes),\n",
    "            }))\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together to serialize the data to tf.records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "out_path_template = 'AOI_5_Khartoum_Train/train_records/aoi5_khartoum_{:04d}.tfrecords'\n",
    "\n",
    "for i, (image_fn, geojson_fn) in enumerate(files):\n",
    "    # Create a new file every 200 records\n",
    "    if i % 200 == 0:\n",
    "        if i != 0:\n",
    "            writer.close()\n",
    "        writer = tf.io.TFRecordWriter(out_path_template.format(i))\n",
    "    \n",
    "    image = gdal.Open(image_fn)\n",
    "    n_x = image.RasterXSize\n",
    "    n_y = image.RasterYSize\n",
    "    gref = gp.Georeference(image.GetGeoTransform())\n",
    "    \n",
    "    # Parse the boxes\n",
    "    boxes = geojson_to_bboxes(geojson_fn, gref, n_x, n_y)\n",
    "    if len(boxes) != 0:\n",
    "        boxes = np.stack(boxes).astype('float32')\n",
    "    \n",
    "        # Strip out the filename\n",
    "        name = os.path.split(os.path.splitext(files[0][1])[0])[1]\n",
    "\n",
    "        # Load and scale the pixel data\n",
    "        pixels = scale_to_8bit(image.ReadAsArray())\n",
    "        pixels = pixels.transpose(1, 2, 0) # Band axis is different to GDAL\n",
    "\n",
    "        # Serialize and write to file\n",
    "        record = encode_sample(name, pixels, boxes)\n",
    "        writer.write(record.SerializeToString())\n",
    "\n",
    "writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h AOI_5_Khartoum_Train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -hault AOI_5_Khartoum_Train/train_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -f AOI_5_Khartoum_Train/train_records/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset('AOI_5_Khartoum_Train/train_records/aoi5_khartoum_1000.tfrecords')\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "    'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "    'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "}\n",
    "\n",
    "sequence_features = {\n",
    "    'image/object/bbox/xmin': tf.io.FixedLenSequenceFeature([], tf.float32),\n",
    "    'image/object/bbox/xmax': tf.io.FixedLenSequenceFeature([], tf.float32),\n",
    "    'image/object/bbox/ymin': tf.io.FixedLenSequenceFeature([], tf.float32),\n",
    "    'image/object/bbox/ymax': tf.io.FixedLenSequenceFeature([], tf.float32),\n",
    "#     'image/object/class/text': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     'image/object/class/label': tf.io.FixedLenFeature([], tf.int64),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_image_dataset = raw_dataset.map(_parse_image_function)\n",
    "parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "\n",
    "image_feature = list(parsed_image_dataset)[0]\n",
    "image_raw = tf.image.decode_jpeg(image_feature['image/encoded']).numpy()\n",
    "height = image_feature['image/height'].numpy()\n",
    "width = image_feature['image/width'].numpy()\n",
    "image = np.frombuffer(image_raw, np.uint8)\n",
    "\n",
    "xmins = tf.sparse.to_dense(image_feature['image/object/bbox/xmin'], default_value=0).numpy()\n",
    "ymins = tf.sparse.to_dense(image_feature['image/object/bbox/ymin'], default_value=0).numpy()\n",
    "xmaxs = tf.sparse.to_dense(image_feature['image/object/bbox/xmax'], default_value=0).numpy()\n",
    "ymaxs = tf.sparse.to_dense(image_feature['image/object/bbox/ymax'], default_value=0).numpy()\n",
    "\n",
    "bs = np.column_stack([ymins, xmins, ymaxs, xmaxs])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image.reshape(height, width, 3))\n",
    "draw_boxes(bs, ax)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
